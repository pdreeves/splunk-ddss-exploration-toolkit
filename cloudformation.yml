---
AWSTemplateFormatVersion: 2010-09-09
Description: This is a CloudFormation template to create an S3 bucket for DDSS storage if it does not already exist, and the necessary AWS resources to query for information about objects in that bucket and send that information to Splunk.

Parameters:

  service:
    Type: String
    Description: Service name used in tagging AWS resources.
    Default: splunk-ddss-exploration-tooklit

  stage:
    Type: String
    Description: Used to distinguish between stages of an environment (dev, test, prod, stage, etc).  Only used in AWS resource tagging.
    Default: dev

  contact:
    Description: Used to identify a contact for the resources created in this stack.  Only used in AWS resource tagging.  As an example, this could be an email address or username.
    Type: String
    Default: ""

  newS3BucketName:
    Type: String
    Description: Name of the existng S3 bucket you want to send DDSS data to.  Leave this blank if the bucket already exists.
    Default: ""

  existingS3BucketName:
    Type: String
    Description: Name of the existng S3 bucket you have DDSS data in.  Leave this blank to create a new S3 bucket.  If you specify the name of an existing S3 bucket, you'll need to create the S3 > SQS notification settings.
    Default: ""

  objectExpirationInDays:
    Description: How many days to keep the objects in S3 before they're deleted.  This only applies to new buckets and not existing buckets.
    Default: 365
    Type: String

  s3TransitionInDays:
    Description: How many days to keep the objects in S3 Standard before they're moved to another storage class.  The default, 1, will move them ASAP.
    Default: 1
    Type: String

  s3TransitionStorageClass:
    Description: What storage class to move objects to.  Please refer to the AWS documentation (https://aws.amazon.com/s3/storage-classes/) for information on different storage classes.
    Default: "GLACIER"
    Type: String
    AllowedValues:
      - GLACIER
      - DEEP_ARCHIVE
      - GLACIER_IR
      - INTELLIGENT_TIERING
      - ONEZONE_IA
      - STANDARD_IA

  splunkPrincipal:
    Description: Principal defined in the AWS S3 bucket policy Splunk generates as part creating the new self storage location.
    Type: String

  splunkHECEndpoint:
    Type: String
    Description: Destination URL that Firehose will send data to.

  splunkHECToken:
    Type: String
    Description: HEC token Firehose will use to authenticate data being sent to Splunk.

  splunkIndex:
    Type: String
    Description: Name of the index in Splunk events will be sent to.

  cloudWatchAlertEmail:
    Type: String
    Description: Email address for receiving alerts related to CloudTrail ingestion.  Leave empty for no alerting.
    Default: ""


Conditions:
  createNewS3Bucket: !Equals
    - !Ref existingS3BucketName
    - ""
  useExistingS3Bucket: !Not
    - !Equals
      - !Ref existingS3BucketName
      - ""
  enableAlerting: !Not 
    - !Equals 
      - !Ref cloudWatchAlertEmail
      - ""

Resources:

  # S3 resources
  s3Bucket:
    Type: AWS::S3::Bucket
    Condition: createNewS3Bucket
    Properties:
      AccessControl: Private
      BucketEncryption: 
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      BucketName: !Ref newS3BucketName
      LifecycleConfiguration:
        Rules:
            - Id: !Sub "${newS3BucketName}-cleanup"
              AbortIncompleteMultipartUpload:
                DaysAfterInitiation: 1
              Status: Enabled
            - Id: !Sub "${newS3BucketName}-sendToGlacier"
              Status: Enabled
              ExpirationInDays: !Ref objectExpirationInDays
              Prefix: ""
              Transitions:
              - TransitionInDays: !Ref s3TransitionInDays
                StorageClass: !Ref s3TransitionStorageClass
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      Tags:
      - Key: service
        Value: !Ref service
      - Key: stage
        Value: !Ref stage
      - Key: contact
        Value: !Ref contact

  s3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: createNewS3Bucket
    Properties:
      Bucket: !Ref s3Bucket
      PolicyDocument:
        Statement:
        - Effect: Allow
          Action:
            - s3:ListBucket
          Principal: 
            AWS: !Ref splunkPrincipal
          Resource: !Sub "arn:aws:s3:::${newS3BucketName}"
        - Effect: Allow
          Action:
            - s3:PutObject
          Principal: 
            AWS: !Ref splunkPrincipal
          Resource: !Sub "arn:aws:s3:::${newS3BucketName}/*"

 # Firehose > Splunk resources
  firehose:
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties: 
      DeliveryStreamName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose", !Sub "${newS3BucketName}-firehose"]
      DeliveryStreamType: DirectPut
      SplunkDestinationConfiguration:
        CloudWatchLoggingOptions:
          Enabled: true
          LogGroupName: !Ref firehoseLogGroup
          LogStreamName: "SplunkDelivery"
        HECAcknowledgmentTimeoutInSeconds: 300
        HECEndpoint: !Ref splunkHECEndpoint
        HECEndpointType: "Event"
        HECToken: !Ref splunkHECToken
        RetryOptions:
          DurationInSeconds: 3600
        S3BackupMode: "FailedEventsOnly"
        S3Configuration:
          BucketARN: !If [useExistingS3Bucket, !Sub "arn:aws:s3:::${existingS3BucketName}-firehose", !Sub "arn:aws:s3:::${newS3BucketName}-firehose-backsplash"]
          BufferingHints:
            IntervalInSeconds: 300
            SizeInMBs: 5
          CompressionFormat: "UNCOMPRESSED"
          Prefix: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose", !Sub "${newS3BucketName}-firehose"]
          RoleARN: !GetAtt firehoseIAMRole.Arn

  firehoseIAMPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Action:
          - logs:Describe*
          - logs:PutLogEvents
          Resource: !GetAtt firehoseLogGroup.Arn
        - Effect: Allow
          Action:
          - s3:PutObject
          Resource: !If [useExistingS3Bucket, !Sub "arn:aws:s3:::${existingS3BucketName}-firehose-backsplash/*", !Sub "arn:aws:s3:::${newS3BucketName}-firehose-backsplash/*"]
      ManagedPolicyName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose-iam-policy", !Sub "${newS3BucketName}-firehose-iam-policy"]

  firehoseIAMRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: "Allow"
          Principal:
            Service: "firehose.amazonaws.com"
          Action:
            - sts:AssumeRole
      ManagedPolicyArns:
        - !Ref firehoseIAMPolicy
      RoleName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose-iam-role", !Sub "${newS3BucketName}-firehose-iam-role"]
      Tags:
      - Key: service
        Value: !Ref service
      - Key: stage
        Value: !Ref stage
      - Key: contact
        Value: !Ref contact

  firehoseBacksplashBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose-backsplash", !Sub "${newS3BucketName}-firehose-backsplash"]
      AccessControl: Private
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LifecycleConfiguration:
        Rules:
            - Id: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose-backsplash-cleanup", !Sub "${newS3BucketName}-firehose-backsplash-cleanup"]
              AbortIncompleteMultipartUpload:
                DaysAfterInitiation: 1
              Status: Enabled
      Tags:
      - Key: service
        Value: !Ref service
      - Key: stage
        Value: !Ref stage
      - Key: contact
        Value: !Ref contact

  firehoseLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      LogGroupName: !If [useExistingS3Bucket, !Sub "/aws/kinesisfirehose/${existingS3BucketName}-firehose", !Sub "/aws/kinesisfirehose/${newS3BucketName}-firehose"]
      RetentionInDays: 30

  firehoseLogStream:
    Type: AWS::Logs::LogStream
    Properties: 
      LogGroupName: !Ref firehoseLogGroup
      LogStreamName: "SplunkDelivery"

# Lambda resources
  lambdaFunction:
    Type: AWS::Lambda::Function
    DependsOn: lambdaLogGroup
    Properties:
      Architectures:
        - arm64
      Code:
        ZipFile: |
          import boto3, gzip, json, os, sys, shutil, re, dateutil.parser, time, csv
          # Default Lambda handler
          def handler(event, context):
            print(event)
            return true
      Description: Lambda function for retriving information about DDSS objects, then sending them to Splunk.
      Environment:
        Variables:
          BUCKET_NAME: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}", !Sub "${newS3BucketName}"]
          FIREHOSE_NAME: !Ref firehose
          SPLUNK_INDEX: !Ref splunkIndex
      FunctionName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda", !Sub "${newS3BucketName}-lambda"]
      Handler: index.handler
      MemorySize: 1024
      Role: !GetAtt lambdaIAMRole.Arn
      Runtime: python3.9
      Tags:
      - Key: service
        Value: !Ref service
      - Key: stage
        Value: !Ref stage
      - Key: contact
        Value: !Ref contact
      Timeout: 300

  lambdaIAMPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Action:
          - s3:ListBucket
          Resource: !If [useExistingS3Bucket, !Sub "arn:aws:s3:::${existingS3BucketName}", !Sub "arn:aws:s3:::${newS3BucketName}"]
        - Effect: Allow
          Action:
          - firehose:PutRecord
          - firehose:PutRecordBatch
          Resource: !GetAtt firehose.Arn
        - Effect: Allow
          Action:
          - logs:CreateLogStream
          - logs:PutLogEvents
          Resource: !If [useExistingS3Bucket, !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${existingS3BucketName}-lambda-function", !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${newS3BucketName}-lambda-function"]
      ManagedPolicyName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda-iam-policy", !Sub "${newS3BucketName}-lambda-iam-policy"]

  lambdaIAMRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: "Allow"
          Principal:
            Service: "lambda.amazonaws.com"
          Action:
            - sts:AssumeRole
      ManagedPolicyArns:
        - !Ref lambdaIAMPolicy
      RoleName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda-iam-role", !Sub "${newS3BucketName}-lambda-iam-role"]
      Tags:
      - Key: service
        Value: !Ref service
      - Key: stage
        Value: !Ref stage
      - Key: contact
        Value: !Ref contact

  lambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !If [useExistingS3Bucket, !Sub "/aws/lambda/${existingS3BucketName}-lambda-function", !Sub "/aws/lambda/${newS3BucketName}-lambda-function"]
      RetentionInDays: 7

# Monitoring resources
  monitoringSNSTopic:
    Condition: enableAlerting
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-alerting-topic", !Sub "${newS3BucketName}-alerting-topic"]
      TopicName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-alerting-topic", !Sub "${newS3BucketName}-alerting-topic"]
      Subscription:
        - Endpoint: !Ref cloudWatchAlertEmail
          Protocol: email

  lambdaInvocationAlarm:
    Condition: enableAlerting
    Type: AWS::CloudWatch::Alarm
    Properties:
      ActionsEnabled: True
      AlarmActions: 
        - !Ref monitoringSNSTopic
      AlarmDescription: !If [useExistingS3Bucket, !Sub "Alarm if lambda function ${existingS3BucketName}-lambda errors out.  Check CloudWatch Logs to verify the function is running correctly.", !Sub "Alarm if lambda function ${newS3BucketName}-lambda errors out.  Check CloudWatch Logs to verify the function is running correctly."]
      AlarmName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda-error-invocations", !Sub "${newS3BucketName}-lambda-error-invocations"]
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
      - Name: FunctionName
        Value: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda", !Sub "${newS3BucketName}-lambda"]
      EvaluationPeriods: 1
      MetricName: Errors
      Namespace: AWS/Lambda
      Period: 60
      Statistic: Sum
      Threshold: 1
      Unit: Count

  lambdaDurationAlarm:
    Condition: enableAlerting
    Type: AWS::CloudWatch::Alarm
    Properties:
      ActionsEnabled: True
      AlarmActions: 
        - !Ref monitoringSNSTopic
      AlarmDescription: !If [useExistingS3Bucket, !Sub "Alarm if lambda function ${existingS3BucketName}-lambda runs over 5 minutes.  Consider tuning the lambda timeout in the CloudFormation template.", !Sub "Alarm if lambda function ${newS3BucketName}-lambda runs over 5 minutes.  Consider tuning the lambda timeout in the CloudFormation template."]
      AlarmName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda-error-duraction", !Sub "${newS3BucketName}-lambda-error-duraction"]
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
      - Name: FunctionName
        Value: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-lambda", !Sub "${newS3BucketName}-lambda"]
      EvaluationPeriods: 1
      MetricName: Duration
      Namespace: AWS/Lambda
      Period: 60
      Statistic: Maximum
      Threshold: 300000
      Unit: Milliseconds

  firehoseDeliveryAlarm:
    Condition: enableAlerting
    Type: AWS::CloudWatch::Alarm
    Properties:
      ActionsEnabled: True
      AlarmActions: 
        - !Ref monitoringSNSTopic
      AlarmDescription: !If [useExistingS3Bucket, !Sub "Alarm if Firehose ${existingS3BucketName}-firehose cannot deliver to Splunk.", !Sub "Alarm if Firehose ${newS3BucketName}-firehose cannot deliver to Splunk."]
      AlarmName: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose-delivery-alarm", !Sub "${newS3BucketName}-firehose-delivery-alarm"]
      ComparisonOperator: LessThanThreshold
      Dimensions:
      - Name: DeliveryStreamName
        Value: !If [useExistingS3Bucket, !Sub "${existingS3BucketName}-firehose", !Sub "${newS3BucketName}-firehose"]
      EvaluationPeriods: 1
      MetricName: DeliveryToSplunk.Success
      Namespace: AWS/Firehose
      Period: 60
      Statistic: Maximum
      Threshold: 1
      Unit: Count


Outputs:
  s3BucketArn:
    Condition: createNewS3Bucket
    Value: !GetAtt s3Bucket.Arn
  firehoseArn:
    Value: !GetAtt firehose.Arn
  firehoseIAMRoleArn:
    Value: !GetAtt firehoseIAMRole.Arn
  firehoseBacksplashBucketArn:
    Value: !GetAtt firehoseBacksplashBucket.Arn
  firehoseLogGroupArn:
    Value: !GetAtt firehoseLogGroup.Arn
  lambdaFunctionArn:
    Value: !GetAtt lambdaFunction.Arn
  lambdaIAMRoleArn:
    Value: !GetAtt lambdaIAMRole.Arn
  lambdaLogGroupArn:
    Value: !GetAtt lambdaLogGroup.Arn
  monitoringSNSTopicArn:
    Condition: enableAlerting
    Value: !Ref monitoringSNSTopic